### 短连接



http://dwz.wailian.work/



1. [使用新浪API生成短连接](https://www.cnblogs.com/Jimmy-pan/p/5784611.html)





#### github  命令行更新流程



更新流程



下载

。。。

修改

。。。



```
git  add   t.json 
git commit -m "0912"
git push -u origin master

```



```
echo "# test" >> README.md
git init
git add README.md
git commit -m "first commit"
git remote add origin https://github.com/baiying9188/test.git
git push -u origin master
```





# lvm/clang

安装cmake 



https://cmake.org/files/v3.11/

```
yum remove cmake
wget http://www.cmake.org/files/v2.8/cmake-2.8.11.2.tar.gz
#tar -xzvf cmake-2.8.11.2.tar.gz
#cd cmake-2.8.11.2
#./configure
#make
#make install
```

解决方法：

 

解决方法：

1、rpm 安装

下载wget的RPM包：

32位：http://mirrors.163.com/centos/6.3/os/i386/Packages/wget-1.12-1.4.el6.i686.rpm

6432位：http://mirrors.163.com/centos/6.3/os/x86_64/Packages/wget-1.12-1.4.el6.x86_64.rpm

rpm ivh wget-1.12-1.4.el6.i686.rpm 安装即可；64位当然选择wget-1.12-1.4.el6.x86_64.rpm了

2、yum安装
 yum -y install wget





https://www.zhihu.com/question/60299862

## Todo 

1. Elasticsearch初始
2. 参考链接
   1. https://es.xiaoleilu.com/010_Intro/00_README.html
   2. [Elasticsearch 权威指南](https://www.gitbook.com/book/looly/elasticsearch-the-definitive-guide-cn/details)


 [AWS初体验-免费搭建SS](http://blog.csdn.net/f59130/article/details/74014415)

3. [经纬中国投资了哪些项目？](https://www.biaodianfu.com/matrix-partners.html)
4. https://www.matrixpartners.com.cn/index.php/zh/matrix-team/item/133-shaoyibo

## java程序性能优化

参考链接

1. [10种简单的Java性能优化](http://www.importnew.com/16181.html)
2. [35+ 个 Java 代码性能优化总结](http://www.cnblogs.com/qlqwjy/p/7717735.html)
3. [Java调优经验谈](http://www.importnew.com/22336.html)
4. [Java内存分析工具--IDEA的JProfiler和JMeter插件](http://blog.csdn.net/wait_notify/article/details/70268194?locationNum=9&fps=1)
5. ​


aws搭建shadowsock教程

https://blog.csdn.net/f59130/article/details/74014415





微信协议

https://wenku.baidu.com/view/10a7280e01f69e3142329425.html



### c_cpp_properties.json

https://www.cnblogs.com/hubery/

https://blog.csdn.net/bat67/article/details/76095813



### wireshark 过滤http包

#  			[Wireshark过滤规则之：http数据包](https://www.cnblogs.com/huanxiyun/articles/6553834.html) 		

#  

http.host==magentonotes.com
http.host contains magentonotes.com
//过滤经过指定域名的http数据包，这里的host值不一定是请求中的域名

http.response.code==302
//过滤http响应状态码为302的数据包

http.response==1
//过滤所有的http响应包

http.request==1
//过滤所有的http请求，貌似也可以使用http.request

http.request.method==POST
//wireshark过滤所有请求方式为POST的http请求包，注意POST为大写

http.cookie contains guid
//过滤含有指定cookie的http数据包

http.request.uri==”/online/setpoint”
//过滤请求的uri，取值是域名后的部分

http.request.full_uri==” http://task.browser.360.cn/online/setpoint”
//过滤含域名的整个url则需要使用http.request.full_uri

http.server contains “nginx”
//过滤http头中server字段含有nginx字符的数据包

http.content_type == “text/html”
//过滤content_type是text/html的http响应、post包，即根据文件类型过滤http数据包

http.content_encoding == “gzip”
//过滤content_encoding是gzip的http包

http.transfer_encoding == “chunked”
//根据transfer_encoding过滤

http.content_length == 279
http.content_length_header == “279″
//根据content_length的数值过滤

http.server
//过滤所有含有http头中含有server字段的数据包

http.request.version == “HTTP/1.1″
//过滤HTTP/1.1版本的http包，包括请求和响应

http.response.phrase == “OK”
//过滤http响应中的phrase





 http and  http.request==1 and  http.request.method==POST and ip.dst == 192.168.1.9



## Wireshark检测不到网卡解决方案

以管理员的权限运行CMD，输入

```bash
net start npf 
```

CMD窗口显示NetGroup Packet FilterDriver 服务已经启动成功。 这样就可以检测到网卡了。

### 关闭WIN10“已计划自动重启”

此电脑->右击 管理->系统工具->任务计划程序->Microsoft->Windows->UpdateOrchestrator->Reboot  任务禁用



### 查看二进制文件

当我们需要把二进制转成c语言中使用的16进制字符数组时，命令xxd是很有用的。

xxd 帮助信息如下：关键选项标黑。

[root@localhost ]# xxd --help
Usage:
       xxd [options][infile [outfile]]
    or
       xxd -r [-s [-]offset][-c cols] [-ps][infile [outfile]]
Options:
    -a          toggle autoskip: A single '*' replaces nul-lines. Default off.
    -b          binary digit dump (incompatible with -p,-i,-r). Default hex.
    -c cols     format <cols> octets per line. Default 16 (-i: 12, -ps: 30).
    -E          show characters in EBCDIC. Default ASCII.
    **-g          number of octets per group in normal output. Default 2**. 每个goup的字节数，默认为2，可设置。
    -h          print this summary.
    **-i          output in C include file style**. ：输出为c包含文件的风格，数组方式存在。
    **-l len      stop after <len> octets.        ：转换到len个字节后停止转换。**    -ps         output in postscript plain hexdump style.
    -r          reverse operation: convert (or patch) hexdump into binary.
    -r -s off   revert with <off> added to file positions found in hexdump.
    -s [+][-]seek start at <seek> bytes abs. (or +: rel.) infile offset.
   **-u          use upper case hex letters. ： 字节大写方式**    -v          show version: "xxd V1.10 27oct98 by Juergen Weigert".

比如运行：

\> xxd -g 1 -i -u -l 10000000 nm.ts > xxd_test.txt

生成的文本显示：

unsigned char __0513_1634_ch32_666_10_ts[] = {
0X47, 0X02, 0X03, 0X13, 0XF8, 0X5A, 0XC5, 0X40, 0X26, 0XE4, 0XD0, 0XDE,
0XAD, 0XB8, 0X76, 0X89, 0X85, 0X23, 0X06, 0X04, 0X6E, 0X05, 0X8B, 0X09,
0XC0, 0X5C, 0X96, 0X4F, 0X18, 0X51, 0X41, 0XC8, 0X40, 0X9F, 0X06, 0X93,
0X38, 0XC1, 0XBB, 0X1A, 0XBC, 0XAC, 0X47, 0XFF, 0X5E, 0X54, 0XEB, 0XA7,
0X14, 0X36, 0X85, 0X8A, 0X90, 0X14, 0X17, 0XA2, 0X9D, 0XC0, 0X84, 0X56,
0XCB, 0X97, 0X78, 0XC8, 0X57, 0X15, 0X3E, 0X61, 0X6F, 0XFE, 0XC9, 0X39,
0XEF, 0XD3, 0XB6, 0X6A, 0XD2, 0XE4, 0XFB, 0X4C, 0X05, 0XF6, 0X03, 0XED,
0X50, 0XB3, 0XE7, 0X46, 0X57, 0X24, 0X71, 0X16, 0X38, 0X45, 0X53, 0X19,
0X56, 0X25, 0X3C, 0X8D, 0X4C, 0XA9, 0X28, 0X9A, 0XB2, 0X99, 0X76, 0X52,
0X28, 0XE9, 0XD6, 0XD6, 0X11, 0X94, 0X89, 0X19, 0X4D, 0XEA, 0X68, 0X76,
0X53, 0XC6, 0XAA, 0X3A, 0XD4, 0XA1, 0X25, 0XA5, 0X03, 0XB0, 0X73, 0XA0,
0XAE, 0X11, 0XC9, 0XBD, 0X37, 0X17, 0X11, 0X5F, 0X30, 0X34, 0X34, 0X0B

.....

};

unsigned int nm.ts_len = 10000000;

另外，在vim中也可以把文件转换为16进制来显示：

:%!xxd

返回正常显示：

:%!xxd -r

 

linux下查看二进制文件
以十六进制格式输出：
od [选项] 文件
od -d 文件  十进制输出
   -o 文件  八进制输出
   -x 文件  十六进制输出
xxd 文件  输出十六进制
在vi命令状态下：
:%!xxd   :%!od    将当前文本转化为16进制格式
:%!xxd -c 12 每行显示12个字节
:%!xxd -r    将当前文本转化回文本格式



### 利用Wireshark任意获取QQ好友IP实施精准定位     

    http://www.freebuf.com/articles/web/137952.html            

https://www.opengps.cn/Data/IP/ipplus.aspx           



> 网址一：[http://chaipip.com/](http://zhainanba.net/go/tz14329-1)
>
> 网址二：[https://www.opengps.cn/Data/IP/LocHighAcc.aspx](http://zhainanba.net/go/tz14329-2)
>
> https://www.maxmind.com/zh/geoip2-precision-demo?ip=113.106.56.189

116.7.225.162     



113.106.56.189



116.24.66.107



https://www.opengps.cn/Data/IP/ipplus.aspx 这个比较准

# 智能广告

###大数据人工智能在数字化营销中的应用



参考链接

1. [目前大数据广告公司的数据来源是哪里？](https://www.zhihu.com/question/21516784)
2. ​

在做相关内容的公司

1. [数果智能](http://sugo.io/)
2. ​



### 0x01 RTB广告行业的产业链中的角色

尽可能的捋清当前互联网广告行业中都有哪些角色，他们的主要提供的服务。



##### 1.广告主/代理商

广告主是指为[推销](http://wiki.mbalib.com/wiki/%E6%8E%A8%E9%94%80)商品或者提供服务，自行或者委托他人设计、制作、发布[广告](http://wiki.mbalib.com/wiki/%E5%B9%BF%E5%91%8A)的[法人](http://wiki.mbalib.com/wiki/%E6%B3%95%E4%BA%BA)、其他经济组织或者个人。

广告主负责提供[市场](http://wiki.mbalib.com/wiki/%E5%B8%82%E5%9C%BA)及[商品](http://wiki.mbalib.com/wiki/%E5%95%86%E5%93%81)资料给[广告代理公司](http://wiki.mbalib.com/wiki/%E5%B9%BF%E5%91%8A%E4%BB%A3%E7%90%86%E5%85%AC%E5%8F%B8)，[监督](http://wiki.mbalib.com/wiki/%E7%9B%91%E7%9D%A3)广告公司的运作过程以及验收[广告](http://wiki.mbalib.com/wiki/%E5%B9%BF%E5%91%8A)[成品](http://wiki.mbalib.com/wiki/%E6%88%90%E5%93%81)。

输出：  广告内容材料，用户画像

##### 2.DSP  Demand-side Platform需求方平台  程序化购需求方平台

面向广告主、广告代理。



##### 3. Ad Exchange  即广告交易平台

面向DSP、SSP，专注于流量交易，进行流量竞价，类似股票交易平台。



##### 4.DMP（Data Management Platform）数据管理平台

一般是第三方平台，提供用户信息的数据、按需进行数据回传。

##### 5.RTB（Real-Time Bidding）实时竞价系统

允许广告主根据投放目标、人群以及费用等因素对每一个广告及每次广告展示的费用进行竞价。

##### 6.SSP Sell-side Platform销售方平台

面向广告位置提供者即广告资源方，使之可以获得最高的有效每千次展示费用。

##### 7.媒体

媒体是指传播信息的媒介。它是指人借助用来传递信息与获取信息的[工具](https://baike.baidu.com/item/%E5%B7%A5%E5%85%B7/81891)、[渠道](https://baike.baidu.com/item/%E6%B8%A0%E9%81%93/85630)、载体、[中介](https://baike.baidu.com/item/%E4%B8%AD%E4%BB%8B)物或技术手段。

1、电视。2、广播。3、报纸。4、周刊（杂志）。5、互联网。6、手机。7、[直邮](https://baike.baidu.com/item/%E7%9B%B4%E9%82%AE)。



#### 国内国外主要AdExchange情况

AdExchange即互联网广告交易平台，它联系着DSP（买方平台）和SSP（卖方平台），通过接入SSP汇集大量媒体流量，是实现精准营销的交易场所。由于成功的AdExchange需要以大量媒体流量为基础，目前其运营商多为互联网巨头。



在国外，主要有雅虎的RightMedia，谷歌的DoubleClick等。一些大型媒体集团倾向于搭建私有广告交易平台，将自己的广告位资源单独出售，以提升对自有媒体资源出售的控制力。如国际媒体巨头新闻集团通过与RubiconProject合作，搭建私有交易平台。



在国内，由于公开交易平台需要汇集大量的媒体，因此往往是网络媒体巨头才能成为公开广告交易平台的运营商。公开广告交易平台上的媒体资源以运营商的媒体合作伙伴资源为主，但同时也可以有运营商自有媒体上的广告位资源。近年来阿里巴巴、新浪、腾讯等网站也纷纷推出了各自的广告交易平台。阿里妈妈于2011年9月正式对外发布Tanx营销平台。随后，腾讯、新浪、盛大、秒针和优酷土豆、百度等广告交易平台纷纷涌现。



#### 知名的Ad Exchanges 平台

谷歌 2012.4 DoubleClick

阿里巴巴 2012.12 TANX

腾讯 2013.1 TAE

百度 2013.8 BES



Ad exchange广告交易平台分类

公开广告交易平台（PublicAdExchange）

以互联网巨头为主当前国内公开广告交易平台的代表主要包括百度、阿里妈妈以及谷歌。它们此前均已运营网站联盟多年，拥有大量的媒体合作伙伴，因此在运营公开广告交易平台上具有天然的优势。



私有广告交易平台（PrivateAdExchange）

以大型门户和视频网站为主国内以大型门户媒体如腾讯、新浪、搜狐，以及视频网站如优酷土豆、爱奇艺、PPTV、暴风科技等为代表，搭建自身私有交易平台。





#### ad exchange 接口

1. http://open.taobao.com/docs/api_list.htm?spm=a219a.7629065.0.0.s7T8Qj&cid=20559
2. [tanx ad exchange api](http://www.doc88.com/p-6069411200842.html)





![](https://pic4.zhimg.com/80/7baf9e396cb4630d309abc941eaace1b_hd.jpg)







![img](http://www.rtbchina.com/wp-content/uploads/2018/01/38841516587440_.pic_hd.png)





#### [Ad Exchange基本接口和功能](http://www.cnblogs.com/lkiversonlk/p/5272788.html)

#### 参考链接

1. [DSP、SSP、DMP、RTB、Ad Exchange ](http://mp.weixin.qq.com/s/P42awQikZwWVVHRBrgqZoA)
2. http://www.rtbchina.com/category/trade-news/ad-exchange
3. [2015互联网广告行业深度分析 ](http://www.sohu.com/a/159581750_155796)              
4. [2018年广告行业市场现状分析 互联网广告增长迅速](https://www.qianzhan.com/analyst/detail/220/180126-b956c81e.html)









### 0x02一次广告展示的流程

我们拿小明举例子，小明最近想买一部新手机，他曾经在网上获某应用上搜索过， 那么DMP 会悄悄get这个信息。



1. 小明打开某款应用XX单车，假设这个时候开屏，要展示一个广告。
2. 应用 发送请求到SSP，声明：我这里有广告位，现在我需要一条广告。时间有限，过时不候。
3. 这个信息会同步到 Ad Exchange  即广告交易平台。 
4. Ad Exchange  为这次广告展示 出价， 我的这次广告展示，最低接收价2元，。。。。 



镜头移动一下，我们说下广告主这边：

广告主 某果，拿到广告公司制作的自己手机的广告。



1. 找到某DSP平台；了解情况后，我打算在你这儿投放广告，预算30W；

2. 好，这个广告开始投放

3. 通过DMP 拿到大数据画像服务，保证我每次的广告成交获取的广告位是一个优质广告位（用户画像匹配）

4. 接下来就可以开始浏览菜市场了AdExchange，在顾问DMP的陪同下。出价

   ​



镜头转移回来，我们接着看小明，

5. 广告位在众多的广告中选中一个出价最高的，完成本次交易（RTB）。 返回广告。
6. 小明打开了应用，后弹出来一条广告
7. 广告展示-->  xx手机就是后，用了之后，腰不酸了，腿不疼了，blablabla.....
8. 感觉不错，继续瞅瞅吧。  点击广告 -> 
9. 接下来，通常是跳转，跳转到商品的可详情可下单界面（比如某东某宝的商品页面）
10. 这次广告完成。








![](https://pic1.zhimg.com/80/c1008fda4ca565e63298fd94667af122_hd.jpg)











**广点通 和 腾讯广告实时交易平台的区别**

1. [腾讯广点通正式发布程序化交易平台GDT Ad Exchange](https://www.baidu.com/s?ie=utf-8&f=8&rsv_bp=0&rsv_idx=1&tn=baidu&wd=%E5%B9%BF%E7%82%B9%E9%80%9A%20%E5%92%8C%20%E8%85%BE%E8%AE%AF%E5%B9%BF%E5%91%8A%E5%AE%9E%E6%97%B6%E4%BA%A4%E6%98%93%E5%B9%B3%E5%8F%B0%E7%9A%84%E5%8C%BA%E5%88%AB%20&rsv_pq=c30e513b0003aacb&rsv_t=bf936j%2F6VlHk7JzNVnpZlyLRkxPcEMQupHQMXGde5StJjFD8gnB%2BtHmmBDY&rqlang=cn&rsv_enter=1&rsv_sug3=12&rsv_sug1=8&rsv_sug7=100&rsv_sug2=0&inputT=34176&rsv_sug4=37936)
2. http://e.qq.com/technology/



### 0x03用户画像

#### 用户画像是什么？

用户画像是是根据用户社会属性、生活习惯和消费行为等信息而抽象出的一个标签化的用户模型。



简单来说，就是用**标签去定义用户**

标签不是越多越好，而是要用有价值的标签去定义人群。



#### 如何获取有价值的标签？

获取标签的途径有三种

1. 算法标签：通过算法建模，利用机器学习，去预测用户的标签。
2. 基础标签：业务通过定义规则，将用户浏览、下单、消费等行为轨迹转化为标签
3. 主动标签：将用户主动填写的信息转化为标签

通过上述方式收集来的标签就可以直接使用了吗?

当然不是，标签清洗后，还需要去验证标签的有效性。

一般来说有以下两种途径：

1. 用样本去测试，如果一个样本的性别是男的，但标签却显示他是女的，这个标签肯定就是错的
2. 看标签的日、周浮动值，根据经验制定标签的浮动阈值，一旦超过了阈值，就需要引起重视

#### 如何应用用户画像？

用户画像的应用面是很广的，个性化推荐，可视化，广告营销等等。所有的应用都离不开一个核心，就是定位用户。用户的时间是非常宝贵的，互联网各个领域的竞争非常激烈，如何把正确的产品推广给正确的人，即是用户画像正确的使用之道。

实践中验证用户模型，调整用户模型



是提升公司的外呼转化率。这个任务要复杂的多，因为影响外呼的转化率的因素是非常多的，外呼的质量、外呼的时间、客服的话术，甚至是天气状况也有可能影响外呼的转化率，如何抽丝剥茧地找到外呼的核心影响因素是完成任务的关键。

1）首先我们将标签以API的形式接入公司的外呼平台，为外呼跟进提供丰富的数据支持，帮助外呼进行客户的分类、管理和销售推进。

2）我们根据现有的大数据去分析影响外呼的关键性指标

3）根据分析结果，建立了算法模型

4）通过大量的A/B测试，去检测和优化模型





#### 参考链接

1. https://zhuanlan.zhihu.com/p/25085063
2. https://zhuanlan.zhihu.com/p/27319371
3. [除了卖身BAT，广告公司还能从哪里获得数据？](http://www.meihua.info/a/69895)






### DMP



#### 什么是DMP

![](https://pic4.zhimg.com/80/v2-c60278d7587eb373a1e120b8b7f138d8_hd.jpg)



#### dmp的组成

![](https://pic2.zhimg.com/80/v2-035703fb80877f751638fcf49567141c_hd.jpg)





QandA

1. dmp输出api是否有标准的接口
2. 用户画像是否有标准格式
3. dmp 底层的数据库  1st Party Data is King





1st Party Data is King

#### 参考链接

1. [2017《程序化广告生态实用手册》白皮书](https://zhuanlan.zhihu.com/p/24808308)
2. [科大讯飞 谭昶：基于AI技术构建的DMP平台与应用](http://www.useit.com.cn/thread-13442-1-1.html)
3. [aliyun,dmp接口](https://help.aliyun.com/knowledge_detail/51388.html?spm=a2c4g.11186631.2.1.AAI5J0)
4. [巧用Superset大数据分析平台搞定各类图表](https://blog.csdn.net/qq273681448/article/details/75050513)





构建DMP平台



## **本质上，IT时代的软件工程和DT时代的数据工程，从总体建设步骤上来说是一致的。**

为此，我们可以从软件工程的流程来分析数据工程，也就是大数据平台的建设步骤。

软件工程建设步骤包括**需求分析、系统设计、系统开发、系统运维**等4大方面。本文主要讲一下前3个方面。

**1、需求分析**

数据需求分为三个层次，分别为业务需求、用户需求、功能需求。各需求要了解清楚大致内容：

- **业务需求**，老板想干啥？是想赚多点钱还是政绩工程？当然一般会是精准营销、个性化服务、提升效率等
- **用户需求**，真正使用这个平台的用户的需求是什么？要什么数据？分析啥？
- **功能需求**，基于业务需求和用户需求推导出大数据平台需要具备哪些功能
- **数据需求**：要接入哪些数据？指标体系是怎样？数据来源于哪些系统？数据量大概什么量级？日增量大概多少？数据接口是怎样的？

**2、系统设计**

基于需求分析的输出设计大数据平台，设计步骤主要包含4个子环节：

- **技术选型**，技术选型主要考虑3个输入：数据量、查询性能要求、实时性要求等，由此决定是采用传统数据仓库还是分布式架构，同时还需考虑资金和团队的因素，如果有钱可采用商用平台和服务，没钱但有技术团队，可采用开源方案，没钱又没团队可以洗洗睡了。
- **技术架构设计**，采集、存储、计算、交互式查询、机器学习等场景分别采用什么技术？同时各技术的集成性需要考虑。
- **数据架构设计**，数据主题、数据分层、数据流、数据交换方式等等
- **数据应用设计**，也就是上层数据应用的功能设计，这个和软件差不多，但基于数据的应用设计还是有很多不同的考虑，在此不做赘述。

**3、系统开发**

- **平台部署：**部署hadoop等大数据平台；
- **数据集成及处理开发：**开发ETL，从数据源采集数据，并做清洗、标准化形成主题库，并根据主题库的标准数据，根据上层数据应用需求，处理成相应的专题库（也叫数据集市）；
- **数据服务开发：**开发并发布上层所需的数据服务接口，供上层数据应用调用；
- **数据应用开发：**基于数据服务、数据集，开发数据应用；










[大数据处理平台Hadoop之安装（基于ubuntu的Hadoop2.9.0，2.X.X同适用）](https://blog.csdn.net/edwinbalance/article/details/78640323)









谈到大数据，相信大家对Hadoop和Apache Spark这两个名字并不陌生。但我们往往对它们的理解只是提留在字面上，并没有对它们进行深入的思考，下面不妨跟我一块看下它们究竟有什么异同。

### **解决问题的层面不一样**

首先，Hadoop和Apache Spark两者都是大数据框架，但是各自存在的目的不尽相同。Hadoop实质上更多是一个分布式数据基础设施: 它将巨大的数据集分派到一个由普通计算机组成的集群中的多个节点进行存储，意味着您不需要购买和维护昂贵的服务器硬件。

同时，Hadoop还会索引和跟踪这些数据，让大数据处理和分析效率达到前所未有的高度。Spark，则是那么一个专门用来对那些分布式存储的大数据进行处理的工具，它并不会进行分布式数据的存储。

### **两者可合可分**

Hadoop除了提供为大家所共识的HDFS分布式数据存储功能之外，还提供了叫做MapReduce的数据处理功能。所以这里我们完全可以抛开Spark，使用Hadoop自身的MapReduce来完成数据的处理。

相反，Spark也不是非要依附在Hadoop身上才能生存。但如上所述，毕竟它没有提供文件管理系统，所以，它必须和其他的分布式文件系统进行集成才能运作。这里我们可以选择Hadoop的HDFS,也可以选择其他的基于云的数据系统平台。但Spark默认来说还是被用在Hadoop上面的，毕竟，大家都认为它们的结合是最好的。

*以下是天地会珠海分舵从网上摘录的对MapReduce的最简洁明了的解析:*

> 我们要数图书馆中的所有书。你数1号书架，我数2号书架。这就是“Map”。我们人越多，数书就更快。
>
> 现在我们到一起，把所有人的统计数加在一起。这就是“Reduce”。

### **Spark数据处理速度秒杀MapReduce**

Spark因为其处理数据的方式不一样，会比MapReduce快上很多。MapReduce是分步对数据进行处理的: ”从集群中读取数据，进行一次处理，将结果写到集群，从集群中读取更新后的数据，进行下一次的处理，将结果写到集群，等等…“ Booz Allen Hamilton的数据科学家Kirk Borne如此解析。

反观Spark，它会在内存中以接近“实时”的时间完成所有的数据分析：“从集群中读取数据，完成所有必须的分析处理，将结果写回集群，完成，” Born说道。Spark的批处理速度比MapReduce快近10倍，内存中的数据分析速度则快近100倍。

如果需要处理的数据和结果需求大部分情况下是静态的，且你也有耐心等待批处理的完成的话，MapReduce的处理方式也是完全可以接受的。

但如果你需要对流数据进行分析，比如那些来自于工厂的传感器收集回来的数据，又或者说你的应用是需要多重数据处理的，那么你也许更应该使用Spark进行处理。

大部分机器学习算法都是需要多重数据处理的。此外，通常会用到Spark的应用场景有以下方面：实时的市场活动，在线产品推荐，网络安全分析，机器日记监控等。

### **灾难恢复**

两者的灾难恢复方式迥异，但是都很不错。因为Hadoop将每次处理后的数据都写入到磁盘上，所以其天生就能很有弹性的对系统错误进行处理。

Spark的数据对象存储在分布于数据集群中的叫做弹性分布式数据集(RDD: Resilient Distributed Dataset)中。“这些数据对象既可以放在内存，也可以放在磁盘，所以RDD同样也可以提供完成的灾难恢复功能，”Borne指出。









------

### 0x06   CentOS 7 使用iptables 开放端口	

CentOS 7.0默认使用的是firewall作为防火墙，这里改为iptables防火墙。

1、关闭firewall：

systemctl stop firewalld.service

systemctl disable firewalld.service

systemctl mask firewalld.service

 

2、安装iptables防火墙

yum install iptables-services -y

3.启动设置防火墙

\# systemctl enable iptables

\# systemctl start iptables

 

4.查看防火墙状态

systemctl status iptables

5编辑防火墙，增加端口

vi /etc/sysconfig/iptables #编辑防火墙配置文件

-A INPUT -m state --state NEW -m tcp -p tcp --dport 22 -j ACCEPT

-A INPUT -m state --state NEW -m tcp -p tcp --dport 80 -j ACCEPT

-A INPUT -m state --state NEW -m tcp -p tcp --dport 3306 -j ACCEPT



 

3.重启配置，重启系统

systemctl restart iptables.service #重启防火墙使配置生效

systemctl enable iptables.service #设置防火墙开机启动





#### 使用命令控制端口



```
/sbin/iptables -I INPUT -p tcp --dport 80 -j ACCEPT    打开端口 80
/etc/init.d/iptables save  保存修改
service iptables restart  重启防火墙，修改生效

/sbin/iptables -I INPUT -p tcp --dport 80 -j DROP    关闭端口
```





### 0x05 linux 命令行工具jq

#### 安装

```
git clone https://github.com/stedolan/jq.git
cd jq
autoreconf -i
./configure --disable-maintainer-mode
make
sudo make install
```

#### 参考链接

1. [jq官网](https://stedolan.github.io/jq/)

2. https://www.cnblogs.com/yy20141204bb/p/4939164.html

3. 手册： https://stedolan.github.io/jq/manual/#example2

   ####  

   打印多个元素

   ```
   jq  .ipclient,.insertDate
   ```



   ```
   cat      /home/data/web/adApi/Adplatfrom/logs/http/httpLog*.log|grep  -v  kaipingdemo   |grep  "height..:" |head -n 500   |jq .content  |sed 's/\\"/\"/g'  |sed 's/.$//'  |sed  's/^.//' | jq .data.adspace[0].creative[0].banner | jq .width,.height
   ```




日志处理命令示例



.content  中是一个json字符串，后面对它进行了置换处理

```
head -n 1  /home/httpLog  |./jq .content |sed 's/\\\"/\"/g'  |sed 's/.$//'  |sed  's/^.//' | ./jq .message
```



```
head -n 1  /home/httpLog  |/jq .content |sed 's/\\\"/\"/g'  |sed 's/.$//'  |sed  's/^.//' | jq .message
```



### 0x04 mysql 忘记密码，修改密码

vim  /etc/mysql/mysql.conf.d/mysqld.cnf 

在[mysqld]段下加入一行“skip-grant-tables”

```
use mysql 
update mysql.user set authentication_string=password('new_pass') where user='root';

flush privileges;

```

把刚才加入的那一行“skip-grant-tables”注释或删除掉。

`service mysql restart`

启动：sudo service mysql start
停止：sudo service mysql stop





### 参考链接

1. [Python 操作 MySQL 的正确姿势](http://www.cnblogs.com/liuliliuli2017/p/6763988.html)
2. https://www.cnblogs.com/wt11/p/6141225.html









### 0x03进程内缓存和进程外缓存的对比

对比redis缓存和本地内存

这两者是什么，

在java应用中，对于访问频率比较高，又不怎么变化的数据，常用的解决方案是把这些数据加入缓存。相比DB,缓存的读取效率快好不少。java应用缓存一般分两种，一是进程内缓存，就是使用java应用虚拟机内存的缓存；另一个是进程外缓存，现在我们常用的各种分布式缓存。相比较而言，进程内缓存比进程外缓存快很多，而且编码也简单；但是，进程内缓存的存储量有限，使用的是java应用虚拟机的内存，而且每个应用都要存储一份，有一定的资源浪费。进程外缓存相比进程内缓存，会慢些，但是，存储空间可以横向扩展，不受限制。



进程内缓存和进程外缓存，各有优缺点，针对不同场景，可以分别采用不同的缓存方案。对于数据量不大的，我们可以采用进程内缓存。或者只要内存足够富裕，都可以采用，但是不要盲目以为自己富裕，不然可能会导致系统内存不够。



#### 数据访问时间的数量级别

|      | 事件                             | 时间     |
| ---- | -------------------------------- | -------- |
| 1    | 从数据库中读取一条数据（有索引） | 十几毫秒 |
| 2    | 从远程分布式缓存读取一条数据     | 0.5毫秒  |
| 3    | 从内存中读取1MB数据              | 十几微妙 |

#### 插入一组数据做位参考

平均单次请求的时间，机器配置相关（i5  8GB的pc）

| 使用的缓存 | t=某次的数据，测试的共次数，av=平均数   ns |      |
| ---------- | ------------------------------------------ | ---- |
| 本地缓存   | t=285907391ns,times=2500,av=468464138      |      |
| redis缓存  | t=465590284ns,times=2653,av=961629872      |      |
| 结论       | 单次请求的时间  本地缓存小于redis 缓存     |      |

测试的方法：

50个线程，每个线程中连续请求10次

| 使用的缓存 |                                               |      |
| ---------- | --------------------------------------------- | ---- |
| 本地缓存   | 请求500，返回500，时间9748ms                  |      |
| redis缓存  | 请求500，返回437，时间 12000ms                |      |
| 结论       | 支持的并发请求数  本地缓存大于  使用redis缓存 |      |



#### 参考链接

1. [java应用本地缓存](http://www.cnblogs.com/sten/p/5734512.html)
2. [Java学习之ConcurrentHashMap实现一个本地缓存](http://www.cnblogs.com/parryyang/p/5779984.html)
3. [高效的找出两个List中的不同元素](http://blog.csdn.net/has330338724/article/details/50532901)
4. [[SqlServer基础之(触发器)](http://www.cnblogs.com/selene/p/4493311.html)](https://www.cnblogs.com/wangprince2017/p/7827091.html)

###  



### 0x02 Java引用赋值，是原子操作吗?  线程安全吗？



#### Q1什么是原子操作

所谓原子操作，就是该操作绝不会在执行完毕前被任何其他任务或事件打断，也就说，它的最小的执行单位，不可能有比它更小的执行单位，因此这里的原子实际是使用了物理学里的物质微粒的概念。



#### Q2非原子的64位操作

这是一个局部的概念，大多地方我们遇不到这样的说法

当线程在没有同步的情况下读取变量时，可能会得到一个失效值，但至少这个值是由之前某个线程设置的值，而不是一个随机值。这种安全性保证也被称为最低安全性( out-of-thin-air safety)。

最低安全性适用于绝大多数变量，但是存在一个例外：非volatile 类型的64位数值变量（double和long，请参见3.1.4节）。Java内存模型要求，变量的读取操作和写入操作都必须是原子操作，但对于非volatile类型的long和double变量，JVM允许将64位的读操作或写操作分解为两个32位的操作。当读取一个非volatile类型的long变量时，如果对该变量的读操作和写操作在不同的线程中执行，那么很可能会读取到某个值的高32位和另一个值的低32位。因此，即使不考虑失效数据问题，在多线程程序中使用共享且可变的long和double等类型的变量也是不安全的，除非用关键字volatile来声明它们，或者用锁保护起来。



#### Q3 Java中 有哪些数据类型，它们分别占用的空间大小是多少

**一、基本数据类型：**

**byte**：Java中最小的数据类型，在内存中占8位(bit)，即1个字节，取值范围-128~127，默认值0

**short**：短整型，在内存中占16位，即2个字节，取值范围-32768~32717，默认值0

**int**：整型，用于存储整数，在内在中占32位，即4个字节，取值范围-2147483648~2147483647，默认值0

**long**：长整型，在内存中占64位，即8个字节-2^63~2^63-1，默认值0L

**float**：浮点型，在内存中占32位，即4个字节，用于存储带小数点的数字（与double的区别在于float类型有效小数点只有6~7位），默认值0

**double**：双精度浮点型，用于存储带有小数点的数字，在内存中占64位，即8个字节，默认值0

**char**：字符型，用于存储单个字符，占16位，即2个字节，取值范围0~65535，默认值为空

**boolean**：布尔类型，占1个字节，用于判断真或假（仅有两个值，即true、false），默认值false

**二、引用数据类型：**

类、接口类型、数组类型、枚举类型、注解类型。

区别：

**基本数据类型**在被创建时，在栈上给其划分一块内存，将数值直接存储在栈上。

**引用数据类型**在被创建时，首先要在栈上给其引用（句柄）分配一块内存，而对象的具体信息都存储在堆内存上，然后由栈上面的引用指向堆中对象的地址。

例如，有一个类Person,有属性name,age,带有参的构造方法，

Person p = new Person("zhangsan",20);

在内存中的具体创建过程是：

1.首先在栈内存中位其p分配一块空间;

2.在堆内存中为Person对象分配一块空间，并为其三个属性设初值""，0；

3.根据类Person中对属性的定义，为该对象的两个属性进行赋值操作；

4.调用构造方法，为两个属性赋值为"Tom",20；（注意这个时候p与Person对象之间还没有建立联系）；

5.将Person对象在堆内存中的地址，赋值给栈中的p;通过引用（句柄）p可以找到堆中对象的具体信息。

相关知识：

**静态区：** 保存自动全局变量和 static 变量（包括 static 全局和局部变量）。静态区的内容在总个程序的生命周期内都存在，由编译器在编译的时候分配。

**堆区：**  一般由程序员分配释放，由 malloc 系列函数或 new 操作符分配的内存，其生命周期由 free 或 delete 决定。在没有释放之前一直存在，直到程序结束，由OS释放。其特点是使用灵活，空间比较大，但容易出错

**栈区：** 由编译器自动分配释放，保存局部变量，栈上的内容只在函数的范围内存在，当函数运行结束，这些内容也会自动被销毁，其特点是效率高，但空间大小有限

**文字常量区：** 常量字符串就是放在这里的。   程序结束后由系统释放。



#### Q4有哪些操作是原子操作

有一些操作比如 int 变量的赋值，引用对象的赋值，

这些的开销很小，甚至我们似乎可以把他们理解为原子性的操作。它们在某些平台是原子性的。

但最后的结论应是：

除非代码所工作的操作系统平台环境或者java官方指定这个操作是原子性操作，线程安全的。我们不应该把它当做原子性的操作，线程安全性的操作。

那么引用进行赋值不是线程安全的，不是原子性的。至少java没有这样答应我们，因为它提供了原子操作类

JDK1.5之后的java.util.concurrent.atomic包里，多了一批原子处理类。

- 标量类：AtomicBoolean，AtomicInteger，AtomicLong，AtomicReference
- 数组类：AtomicIntegerArray，AtomicLongArray，AtomicReferenceArray
- 更新器类：AtomicLongFieldUpdater，AtomicIntegerFieldUpdater，AtomicReferenceFieldUpdater
- 复合变量类：AtomicMarkableReference，AtomicStampedReference

AtomicBoolean，AtomicInteger，AtomicLong，AtomicReference这四种基本类型用来处理布尔，整数，长整数，对象四种数据，其内部实现不是简单的使用synchronized，而是一个更为高效的方式CAS
 (compare and swap) + volatile和native方法，从而避免了synchronized的高开销，执行效率大为提升。

#### 结论

其实发现是自己跟自己挖了一个坑，答案很简单。

除非代码所工作的操作系统平台环境或者java官方指定这个操作是原子性操作，线程安全的。我们不应该把它当做原子性的操作，线程安全性的操作。

基于CAS的线程安全机制很好很高效，但要说的是，并非所有线程安全都可以用这样的方法来实现，这只适合一些粒度比较小，型如计数器这样的需求用起来才有效





### 0x01 centos7 设置静态IP

临时修改IP

ifconfig en160   192.168.1.101 

永久修改IP

第一步：查看网络接口

ifconfig  

ip addr

第二步：修改配置文件

vim /etc/sysconfig/network-scripts/ifcfg-网络接口名称

修改以下配置

/etc/sysconfig/network-scripts/ifcfg-ens160

```
TYPE=Ethernet
NM_CONTROLLED=no
PROXY_METHOD=none
BROWSER_ONLY=no
BOOTPROTO="static"
BROADCAST="192.168.1.255"
DNS="192.168.1.1"
GATWAY="192.168.1.1"
IPADDR=192.168.1.34
NETMASK=255.255.255.0
DEFROUTE=yes
IPV4_FAILURE_FATAL=no
IPV6INIT=yes
IPV6_AUTOCONF=yes
IPV6_DEFROUTE=yes
IPV6_FAILURE_FATAL=no
IPV6_ADDR_GEN_MODE=stable-privacy
NAME=ens160
UUID=f5eaffee-fbf4-4343-b6c2-69ea3ab76607
DEVICE=ens160
ONBOOT=yes
ZONE=public
PREFIX=24

```



第三步：重启网络服务

```
service  network restart
```

 



# 命令使用

### 0x03 screen  命令的使用



一、使用Screen创建一个Session

　　screen -S sessionName 注：sessionName是要删除的session名字

二、结束一个Screen创建的session

1、首先使用screen -ls命令查看全部session列表

2、使用screen -S sessionName -X quit, 注：sessionName是要删除的session名字

 

三、恢复一个Screen的session

1、Screen -r sessionName



screen -S yourname -> 新建一个叫yourname的session

            screen -ls -> 列出当前所有的session
    
            screen -r yourname -> 回到yourname这个session
    
            screen -d yourname -> 远程detach某个session
    
            screen -d -r yourname -> 结束当前session并回到yourname这个session

**在每个screen session 下，所有命令都以 ctrl+a(C-a) 开始。退出screen使用 exit**例：Ctrl+a,d(按住Ctrl　然后按a　放开a　按d)



## 0x02tcpdump 的简单使用Todo

tcpdump -i em1



监听 8200 端口的http 请求和应答

```
tcpdump -i em1  -A -s 0 'tcp port 8200 and (((ip[2:2] - ((ip[0]&0xf)<<2)) - ((tcp[12]&0xf0)>>2)) != 0)'
```





X-Real-IP: 101.37.172.219
X-Forwarded-For: 101.37.172.219





1.监听eth0网卡HTTP 80端口的request和response
tcpdump -i eth0 -A -s 0 'tcp port 80 and (((ip[2:2] - ((ip[0]&0xf)<<2)) - ((tcp[12]&0xf0)>>2)) != 0)'

2.监听eth0网卡HTTP 80端口的request(不包括response)，指定来源域名"example.com"，也可以指定IP"192.168.1.107"
tcpdump -i eth0 -A -s 0 'src example.com and tcp port 80 and (((ip[2:2] -
 ((ip[0]&0xf)<<2)) - ((tcp[12]&0xf0)>>2)) != 0)'

3.监听本机发送至本机的HTTP 80端口的request和response
tcpdump -i lo -A -s 0 'tcp port 80 and (((ip[2:2] - ((ip[0]&0xf)<<2)) - ((tcp[12]&0xf0)>>2)) != 0)'

4.监听eth0网卡HTTP 80端口的request和response，结果另存为cap文件
tcpdump -i eth0 -A -s 0 'tcp port 80 and (((ip[2:2] - 
((ip[0]&0xf)<<2)) - ((tcp[12]&0xf0)>>2)) != 0)' -w 
./dump.cap



## 0x01命令行json 处理工具jq命令的使用



命令安装： wget http://stedolan.github.io/jq/download/linux64/jq

手册： https://stedolan.github.io/jq/manual/#example2

#### 

打印多个元素

```
jq  .ipclient,.insertDate
```



使用：



cat   httpLog*.log|grep  -v  kaipingdemo   |grep  "height..:" |head -n 1   |jq .content  |sed 's/\\\"/\"/g'  |sed 's/.$//'  |sed  's/^.//' | jq .data.adspace[0].creative[0].| jq .banner.width,.height



### 0x00  根据ip获取 地址

http://ip-api.com/json/



http://ip-api.com/json?ip=116.24.67.243





https://dev.maxmind.com/zh-hans/geoip/legacy/geolite/



# 技术路线



### 运维工程师技术路线

描述运维工程师需要掌握的知识点，及相关推荐的图书和书籍





#### 推荐书籍

#### 第一阶段

#### linux基本环境和常用命令及shell编程

1. 《鸟哥的Linux私房菜 基础学习篇》  翻过 不错的书
2. 《redhat linux 用户基础》

#### 常用应用软件的架设和熟悉

1. 《鸟哥的Linux私房菜(服务器架设篇)》 翻过 不错的书

这基本数是我翻过的感觉不错的。也有其他书不错，你可以看看当当网上 或者网上其他地方的推荐。



这一阶段的主要目标是

1. 熟悉linux环境，及常用命令的使用。
2. 常用的服务的搭建和安装使用。如 sshd   http web服务等。
3. 你可以参考下，你那张达内的宣传单上的说明。

怎么开始？

1. 先搭建一个环境，  方式有很多  建议可以在vmware 建立一个ubuntu的虚拟机。 你可以在这个ubuntu虚拟机中，练习操作。
2. 可以一个知识点一个知识点练习，有不懂的可以百度 搜索 或者问朋友。也可以加一些技术群
3. 。。。

参考链接

1. [VMware Workstation12安装Ubuntu 16.04和VMware Tools教程](http://www.linuxidc.com/Linux/2016-11/137241.htm)
2. ​

#### 第二阶段

#### python运维

1. 《Python核心编程 第3版    》   看过，不错的数。  可以系统学习熟悉python的语法和适用
2. 《Python自动化运维：技术与最佳实践   》      没有看过，看目录和评价还不错

#### 数据库

集群

大数据





#### 参考链接

1. [Linux 运维工程师学习成长路线上要经历哪四个阶段？](http://blog.csdn.net/Ki8Qzvka6Gz4n450m/article/details/78764267)
2. [Linux 运维发展前景如何？](https://www.zhihu.com/question/19855673?rf=20200846)



![这里写图片描述](http://s3.51cto.com/wyfs02/M01/71/44/wKioL1XKnBCCQ_Q5AAGTYY3q-kA631.jpg)





