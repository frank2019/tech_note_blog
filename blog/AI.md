todo

1. 李飞飞 视频
2. 吴恩达 课程  图书
3. Python机器学习实践指南



问题

1. [机器学习---分类、回归、聚类、降维的区别](https://blog.csdn.net/u011630575/article/details/78637517)
2. 



![img](https://pic1.zhimg.com/80/v2-a3685a05ccd1517dc402c911b5395cdd_hd.jpg) 

## Python机器学习实践指南

1. [参考代码](https://github.com/PacktPublishing/Python-Machine-Learning-Blueprints)



0x03 



空间聚类算法（DBSCAN）    



### 0x02 构建应用程序，发现低价的公寓

#### 参考链接

1. [如何利用机器学习预测房价？ ](https://www.leiphone.com/news/201709/G7jncGzgKHebUG7i.html)



#### 0、需求目标是什么

1. 根据已知的数据，预测数据集之外的给定的公寓的价格



#### 1.主要步骤

1. 获取房源公寓数据

2. 数据检查和准备

3. 可视化数据

4. 构建回归模型

5. 预测

   



### 0x01 Python机器学习的生态系统

#### 1.机器学习的工作流程

获取，检查和探索，清理和准备， 建模 ，评估，部署

#### 2. 机器学习中常用的Python库

1. request  可以获取网络上的数据

2. numpy 

3. pandas   开源数据分析操作工具

4. Jupyter 交互式计算环境

5. matplotlib Python 会图库的鼻祖

6. seaborn 专门为统计可视化而创建的库 可以和pandas的数据框完美协作

7. statsmodels   用于探索数据 估计模型 并运行统计检验

8. sklearn   即scikit-learn 库  机器学习库

   

#### 3.机器学习环境

1. pip（Python的包管理器） 可以单独安装库
2. Anaconda 针对Python科学栈的用户，'conda update <package_name>'

#### 4.后缀为.ipynb的文件如何运行

//安装依赖的包

```
pip install ipython

pip install "ipython[notebook]"
```

使用下一代版本代替 ipthon

```
pip install jupyter
```



使用

```
jupyter notebook
```



#### 5、Anaconda 的安装使用

##### Anaconda是什么

`Conda`是一个开源的包、环境管理器，可以用于在同一个机器上安装不同版本的软件包及其依赖，并能够在不同的环境之间切换 

Anaconda包括Conda、Python以及一大堆安装好的工具包，比如：`numpy`、`pandas`等 

##### 下载安装

1. [清华镜像下载链接 较快](https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive/)
2. [官网下载链接](https://www.anaconda.com/download/)

配置path环境变量

```
D:\ProgramData\Anaconda3\Scripts
```

##### 使用

修改源

```
conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/
conda config --set show_channel_urls yes
```

此时，目录 C:\Users<你的用户名> 下就会生成配置文件.condarc，内容如下： 

```
channels:
  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/
  - defaults
show_channel_urls: true
```

删除第三行

查看是否生效

通过命令 conda info 查看当前配置信息，内容如下，即修改成功，关注 channel URLs 字段内容



中科大的镜像是：

conda config --add channels https://mirrors.ustc.edu.cn/anaconda/pkgs/free/    



安装完成后，我们还需要对所有工具包进行升级，以避免可能发生的错误。 

```
conda upgrade --all
```

##### 如何管理Python包？

安装一个 package：

```
conda install package_name
```

这里 package_name 是需要安装包的名称。你也可以同时安装多个包，比如同时安装numpy 、scipy 和 pandas，则执行如下命令：

```
conda install numpy scipy pandas
```

你也可以指定安装的版本，比如安装 1.1 版本的 numpy ：

```
conda install numpy=1.10
```

移除一个 package：

```
conda remove package_name
```



升级 package 版本：

```
conda update package_name
```



查看所有的 packages：

```
conda list
```

如果你记不清 package 的具体名称，也可以进行模糊查询：

```bash
conda  search search_term
```

##### 管理Python环境？

默认的环境是 root，你也可以创建一个新环境：

```
conda create -n env_name  list of packages
```

其中 `-n` 代表 name，`env_name` 是需要创建的环境名称，`list of packages` 则是列出在新环境中需要安装的工具包。

例如，当我安装了 Python3 版本的 Anaconda 后，默认的 root 环境自然是 Python3，但是我还需要创建一个 Python 2 的环境来运行旧版本的 Python 代码，最好还安装了 pandas 包，于是我们运行以下命令来创建：

```
conda create -n py2 python=2.7 pandas
```

细心的你一定会发现，py2 环境中不仅安装了 pandas，还安装了 numpy 等一系列 packages，这就是使用 conda 的方便之处，它会自动为你安装相应的依赖包，而不需要你一个个手动安装。

进入名为 env_name 的环境：

```
source activate env_name
```

退出当前环境：

```
source deactivate
```

另外注意，在 Windows 系统中，使用 `activate env_name` 和 `deactivate` 来进入和退出某个环境。

删除名为 env_name 的环境：

```
conda env remove -n env_name
```



显示所有的环境：

```
conda env list
```

当分享代码的时候，同时也需要将运行环境分享给大家，执行如下命令可以将当前环境下的 package 信息存入名为 environment 的 YAML 文件中。

```
conda env export > environment.yaml
```

同样，当执行他人的代码时，也需要配置相应的环境。这时你可以用对方分享的 YAML 文件来创建一摸一样的运行环境。

```
conda env create -f environment.yaml
```





##### 参考链接

1. [Anaconda使用入门](https://www.cnblogs.com/baiyangcao/p/anaconda_basic.html)
2. [致Python初学者们 - Anaconda入门使用指南](https://www.jianshu.com/p/169403f7e40c)



## 机器学习中的数学公式和概念

满秩矩阵 (full-rank matrix)或正走矩阵 (positive definite matrix) 

逆矩阵

 最小二乘



![](http://www.25000li.top/wp-content/uploads/2018/05/3.jpg)

 

## 机器学习实战 Peter

### 0x02  k-近邻算法

1. 简单地说， k-近邻算法采用测量不同特征值之间的距离方法进行分类    

   - 优点：精度高、对异常值不敏感、无数据输入假定。    
   - 缺点：计算复杂度高、空间复杂度高。    
   - 适用数据范围：数值型和标称型。    

2. k-近邻算法（ k-Nearest Neighbor，KNN) ），它的工作原理是：存在一个样本数 据集合，也称作训练样本集，并且样本集中每个数据都存在标签，即我们知道样本集中每一数据 与所属分类的对应关系。输入没有标签的新数据后，将新数据的每个特征与样本集中数据对应的 特征进行比较，然后算法提取样本集中特征最相似数据（最近邻）的分类标签。一般来说，我们 只选择样本数据集中前k个最相似的数据，这就是k-近邻算法中k的出处，通常k是不大于20的整数。 最后，选择k个最相似数据中出现次数最多的分类，作为新数据的分类。    

   前k个是什么意思 ：   计算过距离后排序，距离最近的k个；

3. k-近邻算法的一般流程    

   - (1) 收集数据：可以使用任何方法。 
   - (2) 准备数据：距离计算所需要的数值，最好是结构化的数据格式。 
   - (3) 分析数据：可以使用任何方法。 
   - (4) 训练算法：此步骤不适用于k-近邻算法。 
   - (5) 测试算法：计算错误率。 
   - (6) 使用算法：首先需要输入样本数据和结构化的输出结果，然后运行k-近邻算法判定输 入数据分别属于哪个分类，最后应用对计算出的分类执行后续的处理。    

4. 





### 0x01 机器学习基础

1. 机器学习能让我们从数据集中受到启发，换句话说，我们会利用计算机来彰显数据背后的真实含义 ；   

2. 机器学习在实际中的应用：垃圾邮件过滤，产品推荐，广告相似推荐，图像识别，手写文字识别等。（ps 验证码识别也可以用这个）

3. 移动计算和传感器产生的海量数据意味着未来我们将面临着越来越多的数据，如何从海量数 据中抽取到有价值的信息将是一个非常重要的课题    

4. “我不断地告诉大家，未来十年最热门的职业是统计学家。很多人认为我是开玩笑， 谁又能想到计算机工程师会是20世纪90年代最诱人的职业呢？如何解释数据、处理数 据、从中抽取价值、展示和交流数据结果，在未来十年将是最重要的职业技能，甚至是 大学，中学，小学的学生也必需具备的技能，因为我们每时每刻都在接触大量的免费信 息，如何理解数据、从中抽取有价值的信息才是其中的关键。这里统计学家只是其中的 一个关键环节，我们还需要合理的展示数据、交流和利用数据。我确实认为，能够从数 据分析中领悟到有价值信息是非常重要的。职业经理人尤其需要能够合理使用和理解自 己部门产生的数据。” ——McKinsey Quarterly， 2009年1月 （谷歌公司的首席经济学家）

5. 机器学习可以做的任务：分类，另一项任务是回归，它主要用于预测数值型数据。

   

6. 用于执行分类、回归、聚类和密度估计的机器学习算法

   监督学习的用途

   a. k-近邻算法   		线性回归

   b.朴素贝叶斯算法		局部加权线性回归

   c. 支持向量机    		Ridge 回归    

   d. 决策树    			Lasso 最小回归系数估计    

   无监督学习的用途    

   K-均值    				最大期望算法    

   DBSCAN    			Parzen窗设计    

7. 如何选择合适的算法

   一、使用机器学习 算法的目的，想要算法完成何种任务，    

   二、需要分析或收集的数据是什么。    

8. 一般并不存在最好的算法或者可以给出最好结 果的算法，同时还要尝试不同算法的执行效果。    

9. 开发机器学习应用程序的步骤    

   (1) 收集数据。    

   (2) 准备输入数据    

   (3) 分析输入数据。    

   (4) 训练算法    

   (5) 测试算法    

   (6) 使用算法。    

10. NumPy 函数库    

Darell Huff曾写过一本《如何使用统计学说谎》（How to Lie With Statistics）    





## 《机器学习-周志华 》读书笔记

### 0x04 决策树

1. 决策树学习的目的是为 了产生一棵泛化能力强，即处理未见示例能力强的决策树，其基本流程遵循简 单且直观的"分而治之" (divide-and-conquer)策略    





### 0x03线性模型

#### 1.咱们判断一个模型是线性模型？

a. 线性模型可以是用曲线拟合样本，但是分类的决策边界一定是直线的 

b.区分是否为线性模型， 看响应自变量的参数有几个

c.最简单判别一个模型是否为线性的，只需要判别决策边界是否是直线，也就是是否能用一条直线来划分 

#### 2.线性模型的基本形式是什么？

给定由 d 个属性描述的示例 
$$
x=(x_1;x_2;...;x_d)
$$

线性模型 (linear  model)试图学得一个通过属性的线性组合来进行预测的函数，即

$$
f(x)=w_1x_1 + w_2x_2 +  ... + w_dx_d + b
$$
一般向量形式写成
$$
f(x) = w^Tx + b,
$$
其中 w 和b 学得之后，模型就得到了。

#### 3.常见的线性模型有哪些？

线性回归   ，对数几率回归，线性判别分析，多分类学习，类别不平衡问题

#### 4.线性回归

均方误差有非常好的几何意义?它对应了常用的欧几里得距离或简称"欧 氏距离" (Euclidean distance). 基于均方误差最小化来进行模型求解的方法称 为"最小二乘法" (least squ町e method). 在线性回归中，最小 A乘法就是试图 找到一条直线，使所有样本到直线上的欧氏距离之和最小.    

 



 

 



参考链接

1. [](http://www.math.ucla.edu/~tao/resource/general/115a.3.02f/)

### 0x02 模型评估与选择    

1. 通常我们把分类错误的样本数占样本总数的比例称为"错误率" (error rate) ，即如果在 m 个样本中有 α 个样本分类错误，则错误率 E= α1m; 相应的， 1 一 α1m 称为"精度" (acc旧acy) ，即"精度 =1 一错误率"更一般地，我们把 学习器的实际预测输出与样本的真实输出之间的差异称为"误差" (error), 学习器在训练集上的误差称为"训练误差" (training error)或"经验误 差" (empirical error) ，在新样本上的误差称为"泛化误差" (generalization error).    

2. 过拟合(overfitting)：当学习器把训练样本学得"太 好"了的时候，很可能巳经把训练样本自身的一些特点当作了所有潜在样本都 会具有的一般性质，这样就会导致泛化性能下降这种现象在机器学习中称为 "过拟合" (overfitting). 与"过拟合"相对的是"欠拟合" (underfitting) ;

3. 过拟合是机器学习面临的关键障碍，各类学习算法都必然带有一 些针对过拟合的措施;然而必须认识到，过拟合是无法彻底避免的，我们所能做 的只是"缓解'气或者说减小其风险.    

4. P=NP问题是什么    P就是能在多项式时间内解决的问题，NP就是能在多项式时间验证答案正确与否的问题。用大白话讲大概就是这样。所以P是否等于NP实质上就是在问，如果对于一个问题我能在多项式时间内验证其答案的正确性，那么我是否能在多项式时间内解决它？这个表述不太严谨，但通俗来讲就是如此。

5.   评估方法，预设环境条件：假设我们只有一个包含 m 个样例的数据集 D={(叫 ， Yl) ,(X2,Y2), … 7 (Xm ， Ym)} ， 既要训练，又要测试，怎样才能做到呢?答案是:通过对 D 进行适当 的处理，从中产生出训练集 S 和测试集 T    ；

   **比较**： 自助法在数据集较小、难以有效划分训练/测试集时很有用;自助法产生的数据集改变了初始数据集的分布，这会引入估计偏差.在初始数据量足够时，留出法和交叉验证法更常用一些.    

   **留出法(hold-out)**："留出法" (hold-out)直接将数据集 D 划分为两个互斥的集合?其中一个 集合作为训练集 S，另一个作为测试集 T， 即 D=BUT ， S∩ T= ∮.在 S 上训 练出模型后，用 T 来评估其测试误差，作为对泛化误差的估计.    训练集和测试集之间的分割是问题：   常见做法是将大约 2/3 - 4/5 的 样本用于训练，剩余样本用于测试.    

   **交叉验证法" (cross validation)**先将数据集 D 划分为 k 个大小相似的 互斥子集， 即 D = D1 U D2υ... U D k, Di n Dj = ø (í 手 j ) . 每个子集 Di 都 尽可 能保持数据分布的一致性，即从 D 中 通过分层采样得到. 然后，每次用 k-1 个子集的并集作为训练集?余 F 的那个子集作为测试集;这样就可获得 k 组训练/测试集，从而可进行 k 次训练和测试? 最终返回的是这 k 个测试结果 的均值 显然，交叉验证法评估结果的稳定性和保真性在很大程度上取决于 k 的取值，为强调这一点，通常把交叉验证法称为 " k 折交叉验证" (k-fold cross validat ion). k 最常用 的取值是 10，此时称为 1 0 折交叉验 证 ; 其他常用 的 k 值 有 5、 20 等.  

   **留一法 (Leave-One-Ot比，简称 LOO) **  假 定数据集 D 中包含 m 个样本 3 若令 k=m ， 则得到了交叉验证法的 一 个特例:留一法 (Leave-One-Ot比，简称 LOO) . 显然 ， 留一法不受随机样本划分    方式的影响，因为 m 个样本只有唯一的方式划分为 m 个子集一一每个子集包含 一个样本;留一法使用的训练集与初始数据集相比只少了一个样本，这就使得 在绝大多数情况下，留一法中被实际评估的模型与期望评估的用 D 训练出的模 型很相似.因此，留一法的评估结果往往被认为比较准确.然而，留一法也有其 缺陷:在数据集比较大时，训练 m 个模型的计算开销可能是难以忍受的.

   **"自助法" (bootstrapping) **它直接以自助采样 法 (bootstrap sampling)为基础 [Efron and Tibshirani, 1993]. 给定包含 m 个样 本的数据集 D ， 我们对它进行采样产生数据集 D': 每次随机从 D 中挑选一个 样本 ，将其拷贝放入 D' 然后再将该样本放回初始数据集 D 中，使得该样本在 下次采样时仍有可能被采到;这个过程重复执行 m 次后?我们就得到了包含 m 个样本的数据集 D‘，这就是自助采样的结果.显然 ， D 中有一部分样本会在 D' 中多次出现，而另一部分样本不出现.可以做一个简单的估计，样本在 m 次采 样中始终不被采到的概率是 (1 一1/m) ， 取极限得到  即通过自助来样，初始数据集 D 中约有 36.8% 的样本未出现在采样数据集 D' 中.于是我们可将 D' 用作训练集 ， D\D' 用作测试集;  这样实际评估的模型与 期望评估的模型都使用 m 个训练、样本，而我们仍有数据总量约 1/3 的、没在训 练集中出现的样本用于测试.这样的测试结果，亦称"包外估计" (out-of-bag estimate).    

6. AOC曲线   ROC曲线  自主采样法  t检验  

 。。。。 todo













### 0x01绪论

1. 机器学习 学术形式化的定义： [Mitchell , 1997J 给出了 一个更形式化的定义假 设用 P 来评估计算机程序 在某任务类 T 上的性能， 若一个程序通过利用经验 E 在 T 中任务丰获得了性 能改善，则我们就说关于 T 和 P ， 该程序对 E 进行 了学习 ;
2. 一般地，令 D = {Xl， 町 "..， Xm } 表示包含 m 个示例的数据集，每个 示例由 d 个属性描述(例如上面的西瓜数据使用了 3 个属性)，则每个示例 Xi = (Xi1; Xi2; . . . ; Xid) 是 d 维样本空间 X 中的一个向量 ， Xi ε X ， 其中 Xij 是 凯在第 j 个属性上的取值(例如上述第 3 个西瓜在第 2 个属性上的值是"硬 挺" ), d 称为样本院的"维数" (dimensionality).    
3. 通常假设样本空间中全 体样本服从 A个未知"分布" (distribution) Ð ， 我们获得的每个样本都是独立 地从这个分布上采样获得的，即"独立同分布" (independent and identically distributed，简称 i.i.d.).    
4. 归纳 (induction)与横绎 (deductio丑)是科学推理的两大基本手段.前者是从 特殊到一般的"泛化" (generalization)过程，即从具体的事实归结出一般性规 律;后者则是从一般到特殊的"特化" (specializatio叫过程，即从基础原理推演 出具体状况.    
5. "奥卡姆剃刀" (Occam's razor)是一种常用的、自然科学 研究中最基本的原则，即"若有多个假设与观察一致，则选最简单的那个 ; 对于科学家，奥卡姆剃刀原理还有一种更为常见的表述形式：当你有两个或多个处于竞争地位的理论能得出同样的结论，那么简单或可证伪的那个更好。这一表述也有一种更为常见的强形式：如果你有两个或多个原理，它们都能解释观测到的事实，那么你应该使用简单或可证伪的那个，直到发现更多的证据。对于现象最简单的解释往往比较复杂的解释更正确 。
6. "没有免费的午餐"定理 (No Free Lunch Theorem，简称 NFL 这里的简化论述繁难得多. 定理) [Wolpert, 1996; Wolpert and Macready, 1995].    我们需注意到， NFL 定理有一个重要前提:所有"问题"出现的机会相 同、或所有问题同等重要    
7. 机器学习提供数据分析 能力，云计算提供数据处 理能力，众包提供数据标 记能力.    
8. 美国《新闻周刊》曾对谷歌有一句话评论"它使任何人离任 何问题的答案间的距离变得只有点击一下鼠标这么远    
9. 1952 年，阿瑟·萨缪尔 (Arthur Samuel, 1901- 1990) 在 IBM 公司研制了一个西洋跳棋程序；，萨缪尔跳棋程序不仅在人王智能领域产生了重大影 响，还影响到 整个计算机科学的发展.早期计算机科学研究认为，计算机不可能完成事先没 有显式编程好的任务，而萨缪尔跳棋程序否证了 这个假设 . 另外，这个程序是最 早在计算机上执行非数值计算任务的程序之一，其逻辑指令设计思想极大地影 响 1 IBM 计算机的指令集， 并很快被其他计算机的设计者采用 .   阿瑟·萨缪尔应约 翰·麦 卡锡 第 1 章绪论 (John McCarthy, "人工智能之父" , 1971 年图灵奖得主)之邀， 在标志着 人 工智能学科诞生的达特茅斯会议上介绍这项工作.萨缪尔发明了"机器学习" 这个词，将其定义为"不显式编程地赋予计算机能力的研究领域    









参考链接

1. [数学之美番外篇：平凡而又神奇的贝叶斯方法 ](http://mindhacks.cn/2008/09/21/the-magical-bayesian-method/)
2. 

## 我的思路机器学习



1. [为期一周的机器学习](http://blog.jobbole.com/110684/)
2. https://www.zhihu.com/question/23987009
3. [从0到1：我是如何在一年内无师自通机器学习的?](https://www.leiphone.com/news/201609/SJGulTsdGcisR8Wz.html)
4. 

### 作为一个工程师如何入门机器学习

1. 先从代码入手，从实际应用入手，从熟悉的领域建立一个初步的印象；
2. 在实践中发现理论的不足，逐渐补充；
3. 熟悉常用的机器学习算法，及其适用的领域；
4. 完善掌握机器学习背后的高数 概率统计  线性代数等理论；
5. 

### TODO0x02 机器学习入门





### 0x01机器学习简史

**about** 全面介绍机器学习的发展史，从感知机、神经网络、决策树、SVM、Adaboost到随机森林、Deep Learning。 

**机器学习是人工智能最重要发展分支之一，在科研领域和工业界都是非常热门的课题。**

机器学习是一门跨学科领域，涉及到统计学、计算机科学、最优化理论、信息理论、神经科学、理论物理以及其他领域。同时，机器学习也是一门非常年轻的学科。机器学习的大规模应用仅仅开始于过去二十年。当今，数据科学应用已成为一种职业。就像西部开发一样，拥有则无尽的机会，同时也有伴随着很多迷惑与问题。 

![](http://www.erogol.com/wp-content/uploads/2014/05/test.jpg)



1. 普遍推广机器学习的第一人Hebb，在1949年提出了基于神经心理学习方法，被称为**Hebbian学习理论**。通过简单的解释，研究递归神经网络（RNN）节点之间的相关性。它记录网络上的共性，像记忆一样工作。

2. 在1952年，IBM的亚瑟·塞缪尔（Arthur Samuel）开发了一个西洋棋的程序。 该程序能够通过棋子的位置学习一个隐式模型，为下一步棋提供比较好的走法。 塞缪尔与这个程序对局了很多次，并观察到这个程序在经过一段时间的学习后可以发挥得更好。

   塞缪尔用这个程序驳倒了机器无法超越书面代码，并像人类一样学习模式的论断。 他创造并定义了“机器学习”：

   > 机器学习是一个能使计算机不用显示编程就能获得能力的研究领域。

3. 1957年，Rosenblatt再次提出以神经科学为背景的第二个机器学习模型——感知器，它与今天的机器学习模型更像。当时，这是非常激动人心的发现，实际上它比Hebbian的想法更容易实现。 Rosenblatt用下面几句话介绍了感知器模型：

   > 感知器模型的设计是针对于一般智能系统的一些基本特性，而不会纠缠于一些特定生物体通常情况下未知的特性。[2]

4. 3 年后，Widrow  [发明的**Delta学习规则**载入机器学习史册，该规则很快被用作感知器训练的实践程序。它也被称为**最小二乘问题**。这两个想法的结合创造了一个很好的线性分类器。 然而，感知器模型的热度在1969年被Minsky [3]所取代。他提出了著名的XOR问题，感知器无法对线性不可分割的数据进行分类。  这是Minsky对神经网络社区的反驳。 此后，神经网络的研究一直止步不前，到在80年代才有所突破。 ![](http://www.cs.ru.nl/~ths/rt2/col/h10/draw-LTUdecis.GIF)

5. 尽管早在1973年由Linnainmaa [5] 以“反向自动差异化模式”为名提出了BP思想，但是直到1981年，Werbos  [6]才提出将神经网络特定反向传播（BP）算法应用到多层感知器（MLP）。BP仍然是当今神经网络架构的关键组成部分。有了这些新想法，神经网络的研究再次加速。1985年至1986年间，神经网络研究人员相继提出了采用BP训练多层感知器（MLP）的理念（Rumelhart，Hinton，Williams [7] – Hetch，Nielsen [8]） 

​       ![From Hetch and Nielsen ](http://www.erogol.com/wp-content/uploads/2014/05/Hetch_Nielsen_NN.png)



6. 另一个学派，在1986年，J.R.Quinlan  [9]提出了另一个非常著名的ML算法，我们称之为决策树，更具体地说是ID3算法。这是机器学习另一个主流的闪光点。此外，ID3以软件的形式发布，能够以简单的规则及其明确的推论更好地应用到实际生活中，与黑匣子神经网络模型相反。

   在ID3之后，社区探索了很多不同的可用方案和算法改进（例如ID4，回归树，CART …），而且仍然是机器学习中的活跃话题之一。  ![](http://www.erogol.com/wp-content/uploads/2014/05/Quinlan_ID3.png)

7. 机器学习领域最重要突破之一是Vapnik和Cortes  [10]在1995年提出的支持向量机（网络）（SVM），它具有非常强的理论论证和实证结果。SVM将机器学习社区分为NN（神经网络）和SVM两个派别。 然而在2000年左右，SVM内核化版本提出之后，NN在这两个派别之间的竞争并不容易（我无法找到关于该主题的第一篇文章）。SVM在很多之前用NN模型解决的问题上得出了最佳结果。 此外，与NN模型相比，SVM能够充分利用凸优化，泛化边际理论和内核化的所有深奥知识。  因此，它可以从不同学科中获得巨大的推动力，促进理论和实践的快速发展。 

   ![](http://www.erogol.com/wp-content/uploads/2014/05/SVM_Vapnik.png)

8. NN模型受到的另一次重创是1 9 9  1年Hochreiter的论文[40]和2001年Hochreiter等人的论文[11]，表明在使用BP算法时，NN单位饱和后会发生梯度损失。简单来说，训练NN模型时由于单位饱和，在迭代超过一定数量后冗余，因此NN非常倾向于在短时间的时期过度拟合。

9. 不久之前，Freund和Schapire在1997年提出了另一个实体机器学习模型，该模型采用增强的弱分类器组合，称为Adaboost。当时给这项工作的作者颁发了戈德尔奖。   Adaboost通过易于训练的弱分类器进行训练，给那些难的样本更高的权重。这种模型是许多不同任务的基础，如面部识别和检测。它也是PAC（Probably  Approximately  Correct）理论的一种实现。通常，所谓的弱分类器被Adaboost选为简单的判决树（单个决策树节点）。他们这样介绍Adaboost;

   > 我们研究的模型可以解释为一个广泛的，抽象的扩展的研究在线预测模型到一般决策理论的设置[11]

   

   2001年，Breiman  [2001]探索了另一个综合模型，该模型集合了多个决策树，其中每个决策树的训练集都是从实例集合中随机选择的，每个节点的特征都是从特征集合随机选择的。基于这些特性，该模型被称为随机森林（RF）。RF从理论上和实际上都证明不会产生过拟合。甚至AdaBoost在数据集中有过拟合和离群点时，随机森林能有更好的鲁棒性（有关RF的更多详细信息，请参阅我的旧帖子http://www.erogol.com/randomness-randomforests/）。随机森林在许多不同的领域，如Kaggle比赛中也有很出色的表现。

   随机森林是树预测因子的组合，每棵树取决于独立采样的随机向量，并且森林中的所有树都具有相同的分布。森林的泛化误差a随着森林中树木数量增多而收敛[12]

   随着时间向今天靠近，神经网络（NN）的一个新时代——深度学习已经被商业化了。这个短语只是指具有许多广泛连续层的NN模型。三层的NN模型崛起大致在2005年，由近期和现在的Hinton，LeCun，Bengio，Andrew  Ng和诸多大师结合了许多不同的发现。

   

   #### 下面我列举了一些**机器学习领域重要的概念**

   - GPU编程
   - 卷积NN [18][20] [40]
   - 解卷积网络[21]
   - 算法优化
   - 随机梯度下降[19] [22]
   - BFGS和L-BFGS [23]
   - 共轭梯度下降[24]
   - 反向传播[40] [19]
   - 整流器单元
   - 稀疏性[15] [16]
   - Dropout网 [26]
   - Maxout网[25]
   - 无监督的NN模型[14]
   - 深度信念网[13]
   - 堆叠式自动编码器[16] [39]
   - 去噪NN模型[17]

   结合所有这些想法和未列出的想法，NN  模型能够在对象识别、语音识别、NLP等不同的任务中击败之前的技术。但是应该注意的是，这并不意味着其他ML流派的结束。虽然深度学习的成功故事还在接二连三的上演，但是它在训练成本和调整模型的外部参数方面还有很多争议。此外，由于其简单性，SVM的使用依然非常普遍。  （据说可能会引起很大争议）

   

   在结束之前，我需要再介绍一个比较前沿的 ML  趋势。随着WWW和社交媒体的发展，一个新的术语——大数据出现了，并大大影响了ML研究。由于大数据的数据规模都很大，许多强大的ML算法在相当多的系统中（当然对大型技术公司来说不是这样）是无用的。因此，研究人员提出了一套新的简单模型——dubbed  Bandit Algorithms，被称为强盗算法[27 – 38]（通常都基于在线学习），使学习更容易，适应大规模问题。

   我只是总结了机器学习的发展史。如果你发现错误，不足或没有添加引用的地方，请不要犹豫，可以通过各种方式告诉我。

#### 参考文章

1. [原文：Brief History of Machine Learning](http://www.erogol.com/brief-history-machine-learning/)



## 机器学习训练秘籍笔记

23

### todo秘籍03偏差和方差：误差的两大来源 

20-

1. 机器学习中有两个主要的误差来源：偏差和方差。理解它们将有助于你决定是否要添加数据，以及利用好时间去执行其它的策略来提升性能 ；
2. 通常，算法在开发/测试集上的性能通常比在训练集上要差。 
3. 这里偏差和方差的：假设你的算法在开发集上有  16% 的错误率（84% 精度），我们将这 16% 的错误率分为两部分： 
   - 第一部分是算法在训练集上的错误率。在本例中，它是 15%。我们非正式地将它作为算法的**偏差（bias）** 
   - 第二部分指的是算法在开发集（或测试集）上的表现比训练集上差多少。在本例中，开发集表现比训练集差 1%。我们非正式地将它作为算法的**方差（variance）**。
   - 如果你的目标是5%的错误率，那可以看那些工作需要调整。
4. 在统计学领域有着更多关于偏差和方差的正式定义，但不必担心。粗略地说，偏差指的是算法在大型训练集上的错误率；方差指的是算法在测试集上的表现低于训练集的程度。当你使用均方误差（MSE）作为误差度量指标时，你可以写下偏差和方差对应的两个公式，并且证明**总误差=偏差+方差**。但在处理机器学习问题时，此处给出的偏差和方差的非正式定义已经足够。 
5. 偏差 = 最佳误差率（“不可避免偏差”）+ 可避免的偏差 ；在统计学上，最优错误率也被称为**贝叶斯错误率（Bayes error rate）**，或贝叶斯率。 
6. 处理偏差和方差问题最简单的形式 
   - 如果具有较高的可避免偏差，那么加大模型的规模（例如通过添加层/神经元数量来增加神经网络的大小）。
   - 如果具有较高的方差，那么向训练集增加数据。
7. 加大模型的规模通常可以减少偏差，但也可能会增加方差和过拟合的风险。然而这种过拟合问题通常只在你不使用正则化技术的时候出现。如果你的算法含有了一个精心设计的正则化方法，通常可以安全地加大模型的规模，而不会增加过拟合风险。 
8. 避免使用更大模型的唯一原因就是这将使得计算代价变大。 

### 秘籍0x02基础误差分析  

13-19章

1. **快速构建并迭代你的第一个系统**  试图在一开始就设计和构建出完美的系统会有些困难，不妨先花几天的时间构建并训练一个最基础的系统。 或许这个最基础的系统离我们所能构建的“最佳”系统相去甚远，但研究里面的基础功能也很有价值：你会很快地找到一些线索来帮助决定在什么方向投入时间 

2. 误差分析：根据开发集样本评估想法。  **误差分析**（Error Analysis） 指的是检查算法误分类的开发集样本的过程，以便你找到造成这些误差的原因。这将帮助你确定项目优先级（就像上面的例子提到的）并且获得关于新方向的灵感 。   一个想法对误差是否有改进，可以考虑极限的方式。  把精力放在改进空间最大的区域。

3. 清洗误标注的开发集和测试集样本。   基于统计数据进行决策。

4. 将大型开发集拆分为两个子集，专注其一。  将开发集明确地分为 Eyeball 和 Blackbox 开发两个子集将很有帮助，它使你了解在人为的误差分析过程中 Eyeball 开发集何时开始发生过拟合。  发生过拟合的时候，可以把更多的Blackbox 中的元素放到Eyeball中。

5. Eyeball 开发集应该大到能够让你对算法主要的错误类别有所察觉。如果你正在处理一项人类表现良好的任务（比如识别图像中的猫），下面是一些粗略的指导方案 ：

   - 如果分类器在 Eyeball 开发集上只犯错 10 次，这个开发集就有点小了。只有 10 个错误样本的话，很难准确估计不同错误类别的影响。但如果数据非常少且不能提供更多的 Eyeball 开发集样本时，聊胜于无，这将有助于确立项目的优先级。

   - 如果分类器在 Eyeball 开发集上样本上犯了约 20 次错误，你将会开始大致了解主要的误差来源。

   - 如果有约 50 个错误样本，你将会比较好地了解主要的误差来源。

   - 如果有约 100 个错误样本，你将会很清楚主要的误差来源。我见过有人手动分析更多的错误样本——有时候多达500个。只要你有足够多的数据，这将是无害的。

   Eyeball 开发集的大小将主要取决于你能够手动分析样本的时间，以及你所拥有的访问数据的权限；

6. 小结：**基础误差分析** 

   - 当你开始一个新项目，尤其是在一个你不擅长领域时，很难正确猜测出最有前景的方向。
   - 所以，不要在一开始就试图设计和构建一个完美的系统。相反，应尽可能快（可能在短短几天内）地构建和训练一个基本系统。然后使用误差分析去帮助你识别出最有前景的方向，并据此不断迭代改进你的算法。
   - 通过手动检查约 100 个算法错误分类的开发集样本来执行误差分析，并计算主要的错误类别。用这些信息来确定优先修正哪种类型的错误。
   - 考虑将开发集分为人为检查的 Eyeball 开发集和非人为检查的 Blackbox 开发集。如果在 Eyeball 开发集上的性能比在 Blackbox 开发集上好很多，那么你已经过拟合 Eyeball 开发集，并且应该考虑为其获得更多的数据。
   - Eyeball 开发集应该足够大，以便于算法有足够多的错误分类样本供你分析。对很多应用来说，含有1000-10000个样本的 Blackbox 开发集已足够。
   - 如果你的开发集不够大到可以按照这种方式进行拆分，那么就使用 Eyeball 开发集来用于人工误差分析、模型选择和调超参。



### 秘籍0x01建立开发集和测试集

1-12章

 1. 监督学习（supervised learning）是指使用已标记（labeled）的训练样本  来学习一个从  映射到  的函数。监督学习算法主要包括线性回归（linear regression）、对数几率回归（logistic regression，又译作逻辑回归）和神经网络（neural network）。虽然机器学习的形式有许多种，但当前具备实用价值的大部分机器学习算法都来自于监督学习。   

 2. **训练集（training set）**用于运行你的学习算法。

    **开发集（development set）**用于调整参数，选择特征，以及对学习算法作出其它决定。有时也称为**留出交叉验证集（hold-out cross validation set）**。

    **测试集（test set）**用于评估算法的性能，但不会据此决定使用什么学习算法或参数。

 3. **开发集和测试集的使命就是引导你的团队对机器学习系统做出最重要的改变。** 合理地设置开发集和测试集，使之近似模拟可能的实际数据情况，并处理得到一个好的结果。 

 4.  开发集和测试集应该服从同一分布。

 5. 开发集的规模应该大到足以区分出你所尝试的不同算法间的性能差异。 通常来说，开发集的规模应该在 1,000 到 10,000 个样本数据之间，而当开发集样本容量为 10,000 时，你将很有可能检测到 0.1% 的性能提升。 

 6. 那么测试集的大小又该如何确定呢？它的规模应该大到使你能够对整体系统的性能进行一个高度可信的评估。

 7. 所谓的**单值评估指标（single-number evaluation metric）**有很多，分类准确率就是其中的一种：你在开发集（或测试集）上运行分类器后，它将返回单个的数据值，代表着被正确分类的样本比例。根据这个指标，如果分类器 A 的准确率为 97％，而分类器 B 的准确率为 90%，那么我们可以认为分类器 A 更优秀。 

 8.  **查准率**（Precision，又译作精度）和**查全率**（Recall，又译作召回率）均不是单值评估指标，因为它给出了两个值来对你的分类器进行评估。**多值评估指标**将使算法之间的优劣比较变得更加困，算法团队需要在之间做取舍权衡。 **取平均值或者加权平均值是将多个指标合并为一个指标的最常用方法之一。** 

 9. 优化指标和满意度指标，  利用一定的算法对多个指标进行合并。

 10. 通过开发集和度量指标加速迭代。1.尝试一些关于系统构建的**想法（idea）**。

     2.使用**代码（code）**实现想法。

     3.根据**实验（experiment）**结果判断想法是否行得通。（第一个想到的点子一般都行不通！）在此基础上学习总结，从而产生新的想法，并保持这一迭代过程。

 11. 何时修改开发集、测试集和度量指标： 

     开展一个新项目时，我会尽快选好开发集和测试集，因为这可以帮团队制定一个明确的目标。

     我通常会要求我的团队在不到一周（一般不会更长）的时间内给出一个初始的开发集、测试集和度量指标，提出一个不太完美的方案并迅速采取行动 ，比花过多时间去思考要好很多。但是一周的时间要求并不适用于成熟的应用程序，譬如垃圾邮件过滤。我也见到过一些团队在已经成熟的系统上花费数月的时间来获得更好的开发集和测试集。

     如果你渐渐发现初始的开发集、测试集和度量指标设置与期望目标有一定差距，快速想方法去改进它们。例如你的开发集与度量指标在排序时将分类器 A 排在 B 的前面，然而你的团队认为分类器 B 在实际产品上的表现更加优异，这个时候就需要考虑修改开发集和测试集，或者是你的评估指标了。

     a. **你需要处理的实际数据的分布和开发集/测试集数据的分布情况不同。** 

     b.**你在开发集上过拟合了。** 

     c. **该指标所度量的不是项目应当优化的目标。** 

 12. 什么是过拟合？     举个栗子： 不知道大家在学车的时候教练教倒库和侧方停车的时候有没有教一串口诀：类似于在车窗的XX框切XX杆的时候打满，切XX的时候回正等等，这个口诀可以顺利让你通过科目二，然而换个车或者换个场地，你就发现并没有卵用... 我们说这只是overfit了某个车和某个场地（训练数据），在新的测试集（新车新场地）上的泛化性能为0。  

     ![](C:\Users\mx\Desktop\afa034d52962681db09b4dc1060f8075_hd.jpg)

      

     13. 小结：建立开发集和测试集

     - 选择作为开发集和测试集的数据，应当与你预期在将来获取并良好处理的数据有着相同的分布，但不需要和训练集数据的分布一致。
     - 开发集和测试集的分布应当尽可能一致。
     - 为你的团队选择一个单值评估指标进行优化。需要考虑多项目标时，不妨将它们整合到一个表达式里（比如对多个误差指标取平均），或者定义满意度指标和优化指标。
     - 机器学习是一个高速迭代的过程：在最终令人满意的方案出现前，你可能要尝试很多想法。
     - 拥有开发集、测试集和单值评估指标可以帮你快速评估一个算法，从而加速迭代过程。
     - 当你探索一个全新的应用时，尽可能在一周内建立你的开发集、测试集和指标，而在成熟的应用上则可以花费更长的时间。
     - 传统的 70% / 30% 训练集/测试集划分对大规模数据并不适用，实际上开发集和测试集的比例会远低于 30%。
     - 开发集的规模应当大到能够检测出算法精度的细微改变，但也不用太大；测试集的规模应该大到能够使你对系统的最终性能作出一个充分的估计。
     - 当开发集和评估指标不再能给团队一个正确的导向时，就尽快修改它们：(i) 如果你在开发集上过拟合，则获取更多的开发集数据。(ii) 如果开发集和测试集的数据分布和实际关注的数据分布不同，则获取新的开发集和测试集。 (iii) 如果评估指标不能够对最重要的任务目标进行度量，则需要修改评估指标 

      

      

     ###  

## 资料收集





![](http://www.25000li.top/wp-content/uploads/2018/05/3.jpg)





![](http://www.25000li.top/wp-content/uploads/2018/05/gzh-frank-1.jpg)

欢迎关注我的公众号或者加我微信！

### TODO

1. coursera上Ng 
2. 机器学习实战
3. 机器学习 周志华
4. http://algo.tpai.qq.com/person/home/sign.html



### OTHER

1. [公众号：机器学习训练秘籍](https://mp.weixin.qq.com/s/FjcS8YKuphq39knYdL0qIQ)

2. [斯坦福大学2014机器学习教程中文笔记目录](http://www.ai-start.com/ml2014/)

3. [吴恩达老师的深度学习课程笔记及资源 ](https://github.com/fengdu78/deeplearning_ai_books)

4. [张江 人工智能入门必读的十本书，你读过几本？](http://36kr.com/p/5089913.html)

5. ###### [人工智能爱好者寒假必读书目推荐(10本)](https://blog.csdn.net/wearable_device/article/details/79298078)

6. ###### [kaggle-competitions](https://www.kaggle.com/competitions)

7. ###### 《机器学习实战》《集体智慧编程》《推荐系统实践》 

8. ###### https://tensorflow.google.cn/get_started/premade_estimators

9. ###### [google tensorflow机器学习速成课程](https://developers.google.cn/machine-learning/crash-course/)

   ###### 

**“当你在思考今天应该如何打发时间时，你需要考虑两个问题，一是你所做的事情是否能改变世界；二是你需要学习多少知识。即使到了今天，我也是这样安排自己的时间的。”**

工作之余，吴恩达喜欢用kindle看书，其中收藏了超过1000册以上与工作相关的书。他对人工智能的态度是：**做这么有意思的工作，即使没人付工资也愿意干。**